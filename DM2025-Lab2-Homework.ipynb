{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: 謝舜卿\n",
    "\n",
    "Student ID: 113152012\n",
    "\n",
    "GitHub ID: Megan123123\n",
    "\n",
    "Kaggle name: Megan123123\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "**Syntax:** `###` creates a tertiary heading (H3).\n",
    "\n",
    "[Content for Preprocessing]\n",
    "\n",
    "**Example Syntax for Content:**\n",
    "*   **Bold text:** `**text**`\n",
    "*   *Italic text*: `*text*`\n",
    "*   Bullet point list:\n",
    "    * Item 1\n",
    "    * Item 2\n",
    "\n",
    "Markdown Syntax to Add Image: `![Description of the Image](./your_local_folder/name_of_the_image.png)`\n",
    "\n",
    "![Example Markdown Syntax to Add Image](./pics/example_md_img.png)\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "[Content for Feature Engineering]\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "[Content for Model Explanation]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "[Content for Insights]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /Users/meg/kaggle-competition/data/data_identification.csv /Users/meg/kaggle-competition/data/emotion.csv /Users/meg/kaggle-competition/data/final_posts.json /Users/meg/kaggle-competition/data/samplesubmission.csv /Users/meg/DM2025-Lab2-Exercise/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data shape: (64171, 2)\n",
      "Emotion data shape: (47890, 2)\n",
      "Total posts: 64171\n"
     ]
    }
   ],
   "source": [
    "# Load data files\n",
    "data_dir = './data/'  # Data folder is in the same directory as this notebook\n",
    "\n",
    "# Load split information (train/test labels)\n",
    "split_df = pd.read_csv(data_dir + 'data_identification.csv')\n",
    "print(f\"Split data shape: {split_df.shape}\")\n",
    "\n",
    "# Load emotion labels (training data only)\n",
    "emotion_df = pd.read_csv(data_dir + 'emotion.csv')\n",
    "print(f\"Emotion data shape: {emotion_df.shape}\")\n",
    "\n",
    "# Load posts from JSON\n",
    "with open(data_dir + 'final_posts.json', 'r') as f:\n",
    "    posts_raw = json.load(f)\n",
    "print(f\"Total posts: {len(posts_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse JSON posts structure\n",
    "posts_data = []\n",
    "for record in posts_raw:\n",
    "    post_info = record['root']['_source']['post']\n",
    "    posts_data.append({\n",
    "        'id': post_info['post_id'],\n",
    "        'text': post_info['text']\n",
    "    })\n",
    "\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "print(f\"Posts dataframe shape: {posts_df.shape}\")\n",
    "\n",
    "# Merge all data sources\n",
    "df = posts_df.merge(split_df, on='id', how='left')\n",
    "df = df.merge(emotion_df, on='id', how='left')\n",
    "\n",
    "# Separate train and test sets\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nEmotion distribution in training:\")\n",
    "print(train_df['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# DATA VISUALIZATION: Emotion Distribution\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Visualize emotion distribution\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m emotion_counts = \u001b[43mtrain_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m      8\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      9\u001b[39m sns.barplot(x=emotion_counts.index, y=emotion_counts.values, palette=\u001b[33m'\u001b[39m\u001b[33mviridis\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DATA VISUALIZATION: Emotion Distribution\n",
    "# ========================================\n",
    "\n",
    "# Visualize emotion distribution\n",
    "emotion_counts = train_df['emotion'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=emotion_counts.index, y=emotion_counts.values, palette='viridis')\n",
    "plt.title('Emotion Distribution in Training Data', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Emotion', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for i, v in enumerate(emotion_counts.values):\n",
    "    plt.text(i, v + 100, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print distribution percentages\n",
    "print(\"Emotion Distribution (%):\")\n",
    "print((train_df['emotion'].value_counts(normalize=True) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# DATA VISUALIZATION: Text Length Analysis\n",
    "# ========================================\n",
    "\n",
    "# Calculate text statistics\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Character length distribution\n",
    "axes[0].hist(train_df['text_length'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_title('Character Length Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Characters')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(train_df['text_length'].mean(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: {train_df[\"text_length\"].mean():.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Word count distribution\n",
    "axes[1].hist(train_df['word_count'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].set_title('Word Count Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Words')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].axvline(train_df['word_count'].mean(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: {train_df[\"word_count\"].mean():.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nText Statistics:\")\n",
    "print(train_df[['text_length', 'word_count']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# DATA VISUALIZATION: Word Count by Emotion\n",
    "# ========================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=train_df, x='emotion', y='word_count', palette='Set2')\n",
    "plt.title('Word Count Distribution by Emotion', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Emotion', fontsize=12)\n",
    "plt.ylabel('Word Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics by emotion\n",
    "print(\"\\nAverage word count by emotion:\")\n",
    "print(train_df.groupby('emotion')['word_count'].mean().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data splits for modeling\n",
    "X_train_full = train_df['text'].values\n",
    "y_train_full = train_df['emotion'].values\n",
    "\n",
    "# Create train/validation split (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train_full  # Maintain class distribution\n",
    ")\n",
    "\n",
    "X_test = test_df['text'].values\n",
    "\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Validation set: {len(X_val)}\")\n",
    "print(f\"Test set: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing steps completed above:\n",
    "# - Data loaded, parsed, and merged\n",
    "# - Train/validation/test splits created\n",
    "# - Data visualizations showing emotion distribution and text statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF-IDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TF-IDF features for baseline model\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,      # Limit to top 10,000 features\n",
    "    ngram_range=(1, 2),      # Use unigrams and bigrams\n",
    "    min_df=2,                # Ignore terms appearing in fewer than 2 documents\n",
    "    max_df=0.95,             # Ignore terms appearing in more than 95% of documents\n",
    "    strip_accents='unicode', # Remove accents\n",
    "    lowercase=True           # Convert to lowercase\n",
    ")\n",
    "\n",
    "# Transform training, validation, and test data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF feature shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for deep learning (DistilBERT)\n",
    "# Note: Requires 'transformers' and 'torch' packages\n",
    "# pip install transformers torch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create label mapping for DistilBERT\n",
    "emotions = sorted(train_df['emotion'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(emotions)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"\\nEmotion labels: {emotions}\")\n",
    "print(f\"Label mapping: {label2id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class for DistilBERT\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        # Tokenize text with padding and truncation\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n",
    "# Prepare data for DistilBERT\n",
    "train_df['label'] = train_df['emotion'].map(label2id)\n",
    "\n",
    "# Split for BERT training\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'].tolist(),\n",
    "    train_df['label'].tolist(),\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "print(f\"BERT Train: {len(train_texts)}, Val: {len(val_texts)}, Test: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering steps completed above:\n",
    "# - TF-IDF features created for baseline model (10,000 features with unigrams/bigrams)\n",
    "# - DistilBERT tokenization setup for advanced model\n",
    "# - Custom PyTorch Dataset class defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZATION: Baseline Model Confusion Matrix\n",
    "# ========================================\n",
    "\n",
    "# Create confusion matrix for baseline model\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "emotions_sorted = sorted(set(y_val))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotions_sorted, \n",
    "            yticklabels=emotions_sorted,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Logistic Regression (Baseline)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i, emotion in enumerate(emotions_sorted):\n",
    "    class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
    "    print(f\"{emotion}: {class_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# BASELINE MODEL: Logistic Regression with TF-IDF\n",
    "# ========================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Train Logistic Regression with class balancing\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    random_state=42, \n",
    "    C=1.0,  # Regularization strength\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_val_pred = lr_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Logistic Regression Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ADVANCED MODEL: DistilBERT Fine-tuning\n",
    "# ========================================\n",
    "\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = EmotionDataset(test_texts, tokenizer=tokenizer)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(emotions),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Model loaded and moved to {device}\")\n",
    "print(f\"Total training steps: {total_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses), predictions, true_labels\n",
    "\n",
    "print(\"Training and evaluation functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'train_acc': [], 'train_loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}')\n",
    "    \n",
    "    # Validate\n",
    "    val_acc, val_loss, _, _ = eval_model(model, val_loader, device)\n",
    "    print(f'Val loss: {val_loss:.4f}, Val accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    # Store history\n",
    "    history['train_acc'].append(train_acc.item())\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc.item())\n",
    "    history['val_loss'].append(val_loss)\n",
    "    print()\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on validation set\n",
    "val_acc, val_loss, val_predictions, val_true_labels = eval_model(model, val_loader, device)\n",
    "\n",
    "# Convert numeric labels back to emotion names\n",
    "val_pred_emotions = [id2label[pred] for pred in val_predictions]\n",
    "val_true_emotions = [id2label[label] for label in val_true_labels]\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(val_true_emotions, val_pred_emotions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# GENERATE TEST PREDICTIONS\n",
    "# ========================================\n",
    "\n",
    "# Make predictions on test set using DistilBERT model\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting on test set\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Convert to emotion labels\n",
    "test_pred_emotions = [id2label[pred] for pred in test_predictions]\n",
    "\n",
    "print(f\"Test predictions generated: {len(test_pred_emotions)}\")\n",
    "print(f\"\\nPredicted emotion distribution:\")\n",
    "print(pd.Series(test_pred_emotions).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZATION: Training History\n",
    "# ========================================\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(range(1, EPOCHS + 1), history['train_acc'], 'bo-', label='Train Accuracy', linewidth=2)\n",
    "axes[0].plot(range(1, EPOCHS + 1), history['val_acc'], 'ro-', label='Validation Accuracy', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(range(1, EPOCHS + 1), history['train_loss'], 'bo-', label='Train Loss', linewidth=2)\n",
    "axes[1].plot(range(1, EPOCHS + 1), history['val_loss'], 'ro-', label='Validation Loss', linewidth=2)\n",
    "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {max(history['val_acc']):.4f} at Epoch {history['val_acc'].index(max(history['val_acc'])) + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CREATE SUBMISSION FILE\n",
    "# ========================================\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'].values,\n",
    "    'emotion': test_pred_emotions\n",
    "})\n",
    "\n",
    "# Create submissions directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('./submissions', exist_ok=True)\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('./submissions/distilbert_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created!\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Also save baseline model predictions (optional)\n",
    "# Uncomment if you want to submit baseline predictions\n",
    "# X_test_full_tfidf = tfidf.transform(test_df['text'].values)\n",
    "# baseline_predictions = lr_model.predict(X_test_full_tfidf)\n",
    "# baseline_submission = pd.DataFrame({'id': test_df['id'].values, 'emotion': baseline_predictions})\n",
    "# baseline_submission.to_csv('./submissions/baseline_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZATION: DistilBERT Confusion Matrix\n",
    "# ========================================\n",
    "\n",
    "# Create confusion matrix for DistilBERT\n",
    "cm_bert = confusion_matrix(val_true_emotions, val_pred_emotions)\n",
    "emotion_labels = sorted(set(val_true_emotions))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_bert, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            xticklabels=emotion_labels, \n",
    "            yticklabels=emotion_labels,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - DistilBERT (Advanced Model)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\nPer-class accuracy (DistilBERT):\")\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    class_acc = cm_bert[i, i] / cm_bert[i].sum() if cm_bert[i].sum() > 0 else 0\n",
    "    print(f\"{emotion}: {class_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation completed above:\n",
    "# - Baseline: Logistic Regression with TF-IDF features\n",
    "# - Advanced: Fine-tuned DistilBERT (3 epochs, batch size 16)\n",
    "# - Training visualizations (accuracy/loss curves)\n",
    "# - Confusion matrices for both models\n",
    "# - Test predictions generated and submission file created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZATION: Test Set Predictions Distribution\n",
    "# ========================================\n",
    "\n",
    "# Visualize test predictions distribution\n",
    "test_emotion_counts = pd.Series(test_pred_emotions).value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=test_emotion_counts.index, y=test_emotion_counts.values, palette='mako')\n",
    "plt.title('Predicted Emotion Distribution in Test Data', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Emotion', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(test_emotion_counts.values):\n",
    "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare train and test distributions\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Training': train_df['emotion'].value_counts(),\n",
    "    'Test Predictions': pd.Series(test_pred_emotions).value_counts()\n",
    "})\n",
    "\n",
    "print(\"\\nDistribution Comparison (Train vs Test Predictions):\")\n",
    "print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
